# -*- coding: utf-8 -*-
"""HeroMotoStock.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cr0WrKw9S5S7GMZjEtzuBvgBzT0UCzrw
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datetime as dt
from keras.callbacks import EarlyStopping
from datetime import datetime
import tensorflow as tf
from tensorflow import keras

def plot_series(datelist ,series, format="-", start=0, end=None):
    plt.plot(datelist, series[start:end], format)
    plt.xlabel("Time")
    plt.ylabel("Value")
    plt.grid(True)

from google.colab import drive
drive.mount('/content/gdrive')

dataset= pd.read_csv('gdrive/My Drive/HEROMOTOCO.csv')

dataset

datelist = list(dataset['Date'])
datelist = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in datelist]

plot_series(datelist,dataset['Close'])

Train=dataset['Close']
time = np.array(range(len(Train)))
split_time = int(0.6*len(Train))
time_train = datelist[:split_time]
x_train = Train[:split_time]
time_valid = datelist[split_time:]
x_valid = Train[split_time:]
plt.figure(figsize=(10, 6))
plot_series(time_train, x_train)
plt.show()

def accuracy(x_valid,prediction,retmetric=False):
 MAE=keras.metrics.mean_absolute_error(x_valid,prediction).numpy()
 MSE=keras.metrics.mean_squared_error(x_valid, prediction).numpy()
 print("MSE : ",keras.metrics.mean_squared_error(x_valid, prediction).numpy())
 print("MAE: " ,keras.metrics.mean_absolute_error(x_valid,prediction).numpy())
 if retmetric == True:
  return MAE

naive_forecast =Train[split_time - 1:-1]

plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid, start=0, end=2057)
plot_series(time_valid, naive_forecast)

accuracy(x_valid,naive_forecast)

def moving_average_forecast(series, window_size):
  forecast = []
  for time in range(len(series) - window_size):
    sum=np.sum(series[time: (time + window_size)])
    mva=sum/window_size
    forecast.append(mva)
  return np.array(forecast)

moving_avg = moving_average_forecast(Train, 40)[split_time - 40:]
plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plot_series(time_valid, moving_avg)
accuracy(x_valid,moving_avg)

diff_series = (np.array(Train[90:]) - np.array(Train[:-90]))
diff_time = time[90:]
plt.figure(figsize=(10, 6))
plot_series(diff_time, diff_series)
plt.show()

diff_moving_avg = moving_average_forecast(diff_series, 30)[split_time - 90 - 30:]
plt.figure(figsize=(10, 6))
plot_series(time_valid, diff_series[split_time - 90:])
plot_series(time_valid, diff_moving_avg)
plt.show()

diff_moving_avg_plus_past = Train[split_time - 90:-90] + diff_moving_avg
plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plot_series(time_valid, diff_moving_avg_plus_past)
plt.show()

accuracy(x_valid,diff_moving_avg_plus_past)

diff_moving_avg_plus_smooth_past = moving_average_forecast(Train[split_time - 100:-90], 10) + diff_moving_avg
plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plot_series(time_valid, diff_moving_avg_plus_smooth_past)
plt.show()

accuracy(x_valid,diff_moving_avg_plus_smooth_past)

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  dataset = tf.data.Dataset.from_tensor_slices(series)
  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)
  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))
  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))
  dataset = dataset.batch(batch_size).prefetch(1)
  return dataset

window_size = 90
batch_size = 128
shuffle_buffer_size = len(x_train)

dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)
print(dataset)
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(1000, input_shape=[window_size], activation="relu"), 
    tf.keras.layers.Dense(500, activation="relu"), 
    tf.keras.layers.Dense(1)
])


#lr_schedule = tf.keras.callbacks.LearningRateScheduler(
    #lambda epoch: 1e-8 * 10**(epoch / 20))
optimizer = tf.keras.optimizers.SGD(lr=1e-8)
model.compile(loss="mse", optimizer=optimizer)
history = model.fit(dataset, epochs=100, verbose=2)

forecast = []
for time in range(len(Train) - window_size):
  forecast.append(model.predict(np.array(Train[time:time + window_size])[np.newaxis]))
forecast = forecast[split_time-window_size:]
results = np.array(forecast)[:, 0, 0]
plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plot_series(time_valid, results)

accuracy(x_valid,results)

model = tf.keras.models.Sequential([
  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),
                      input_shape=[None]),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
  tf.keras.layers.Dense(100),
  tf.keras.layers.Dense(1),
  tf.keras.layers.Lambda(lambda x: x * 2500.0)
])

#lr_schedule = tf.keras.callbacks.LearningRateScheduler(
 #   lambda epoch: 1e-8 * 10**(epoch / 20))
optimizer = tf.keras.optimizers.Adam(lr=5e-5)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])
es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=26)
history = model.fit(dataset, epochs=500,verbose=2,callbacks=[es])

plt.semilogx(history.history["lr"], history.history["loss"])
plt.axis([1e-8, 1e-4, 0, 600])

forecast = []
for time in range(len(Train) - window_size):
  forecast.append(model.predict(np.array(Train[time:time + window_size])[np.newaxis]))
forecast = forecast[split_time-window_size:]
results = np.array(forecast)[:, 0, 0]
plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plot_series(time_valid, results)

accuracy(x_valid,results)

