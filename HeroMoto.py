# -*- coding: utf-8 -*-
"""HeroMotoStock.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cr0WrKw9S5S7GMZjEtzuBvgBzT0UCzrw

### **`Import Libraries`**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datetime as dt
from keras.callbacks import EarlyStopping
from datetime import datetime
from google.colab import files
import tensorflow as tf
from tensorflow import keras

"""###**Function to plot basic series**"""

def plot_series(datelist ,series, format="-", start=0, end=None):
    plt.plot(datelist, series[start:end], format)
    plt.xlabel("Time")
    plt.ylabel("Value")
    plt.savefig('new.jpg')
    files.download('new.jpg') 
    plt.grid(True)

"""### Mount and View Data """

from google.colab import drive
drive.mount('/content/gdrive')

dataset= pd.read_csv('gdrive/My Drive/HEROMOTOCO.csv')

dataset

datelist = list(dataset['Date'])
datelist = [dt.datetime.strptime(date, '%Y-%m-%d').date() for date in datelist]

plot_series(datelist,dataset['Close']) ## I chose the closing price as the parameter I want to predict

"""### Spliting into Test and Train"""

Train=dataset['Close']
time = np.array(range(len(Train)))
split_time = int(0.85*len(Train)) 
time_train = datelist[:split_time]
x_train = Train[:split_time]
time_valid = datelist[split_time:]
x_valid = Train[split_time:]
plt.figure(figsize=(10, 6))
plot_series(time_train, x_train)
plt.show()

"""##Accuracy Metric"""

def accuracy(x_valid,prediction,retmetric=False):
 MAE=keras.metrics.mean_absolute_error(x_valid,prediction).numpy()
 MSE=keras.metrics.mean_squared_error(x_valid, prediction).numpy()
 print("MSE : ",keras.metrics.mean_squared_error(x_valid, prediction).numpy())
 print("MAE: " ,keras.metrics.mean_absolute_error(x_valid,prediction).numpy())
 if retmetric == True:
  return MAE

"""### Moving Average Function """

def moving_average_forecast(series, window_size):
  forecast = []
  for time in range(len(series) - window_size):
    sum=np.sum(series[time: (time + window_size)])
    mva=sum/window_size
    forecast.append(mva)
  return np.array(forecast)

moving_avg = moving_average_forecast(Train, 40)[split_time - 40:]
plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plot_series(time_valid, moving_avg)
accuracy(x_valid,moving_avg)

"""### Moving Average with a difference to account for a period in the series"""

diff_series = (np.array(Train[90:]) - np.array(Train[:-90]))
diff_time = time[90:]
plt.figure(figsize=(10, 6))
plot_series(diff_time, diff_series)
plt.show()

diff_moving_avg = moving_average_forecast(diff_series, 30)[split_time - 90 - 30:]  
plt.figure(figsize=(10, 6))
plot_series(time_valid, diff_series[split_time - 90:])
plot_series(time_valid, diff_moving_avg)
plt.show()

diff_moving_avg_plus_past = Train[split_time - 90:-90] + diff_moving_avg ## Adding Back the values
plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plot_series(time_valid, diff_moving_avg_plus_past)
plt.show()

accuracy(x_valid,diff_moving_avg_plus_past)

"""###Smoothening the Training series while adding the Moving Avg"""

diff_moving_avg_plus_smooth_past = moving_average_forecast(Train[split_time - 100:-90], 10) + diff_moving_avg #
plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plot_series(time_valid, diff_moving_avg_plus_smooth_past)
plt.show()

accuracy(x_valid,diff_moving_avg_plus_smooth_past)

"""### Input pipeline"""

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  dataset = tf.data.Dataset.from_tensor_slices(series)
  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)
  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))
  dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))
  dataset = dataset.batch(batch_size).prefetch(1)
  return dataset

window_size = 90
batch_size =  128
shuffle_buffer_size = len(x_train)

"""## Dense Network"""

dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)
print(dataset)
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(1000, input_shape=[window_size], activation="relu"), 
    tf.keras.layers.Dense(500, activation="relu"), 
    tf.keras.layers.Dense(1)
])


#lr_schedule = tf.keras.callbacks.LearningRateScheduler(
    #lambda epoch: 1e-8 * 10**(epoch / 20))
optimizer = tf.keras.optimizers.SGD(lr=1e-8)
model.compile(loss="mse", optimizer=optimizer)
history = model.fit(dataset, epochs=100, verbose=2 )



forecast = []
for time in range(len(Train) - window_size):
  forecast.append(model.predict(np.array(Train[time:time + window_size])[np.newaxis]))
forecast = forecast[split_time-window_size:]
results = np.array(forecast)[:, 0, 0]
plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plot_series(time_valid, results)

accuracy(x_valid,results)

"""### LSTM

####Choosing a learning rate + Window_size + Batch Size
"""

window_size = 90  # Hyperparams
batch_size =  128 # Hyperparams
shuffle_buffer_size = len(x_train)
model = tf.keras.models.Sequential([
  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),
                      input_shape=[None]),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
  tf.keras.layers.Dense(1000,activation="relu"),
   tf.keras.layers.Dense(500,activation="relu"),
  tf.keras.layers.Dense(1),
  tf.keras.layers.Lambda(lambda x: x * 30000.0) 
])

lr_schedule = tf.keras.callbacks.LearningRateScheduler(
    lambda epoch: 5e-6 * 10**(epoch / 20))
optimizer = tf.keras.optimizers.Adam()
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mse"])
history = model.fit(dataset, epochs=100,verbose=2,callbacks=[lr_schedule])

plt.semilogx(history.history["lr"], history.history["loss"])
plt.axis([1e-6, 1e-2, 0, 1000])
plt.savefig('learningrateZoomed.jpg')
files.download('learningrateZoomed.jpg')

window_size = 90  # Hyperparams
batch_size =  256 # Hyperparams
dataset = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)
model = tf.keras.models.Sequential([
  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),
                      input_shape=[None]),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),
  tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
  tf.keras.layers.Dense(1000,activation="relu"),
   tf.keras.layers.Dense(500,activation="relu"),
  tf.keras.layers.Dense(1),
  tf.keras.layers.Lambda(lambda x: x * 30000.0) 
])
optimizer = tf.keras.optimizers.Adam(lr=1e-5)
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mse"])
es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=20)
history = model.fit(dataset, epochs=500,verbose=2,callbacks=[es])

forecast = []
for time in range(len(Train) - window_size):
  forecast.append(model.predict(np.array(Train[time:time + window_size])[np.newaxis]))
forecast = forecast[split_time-window_size:]
results = np.array(forecast)[:, 0, 0]
plt.figure(figsize=(10, 6))
plot_series(time_valid, x_valid)
plot_series(time_valid, results)

accuracy(x_valid,results)
